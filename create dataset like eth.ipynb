{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxC0YTW75kJn",
        "outputId": "2e361dae-864a-4e6e-9f3f-5b0e650d99e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-10-20 18:23:54--  https://www.nuscenes.org/data/v1.0-mini.tgz\n",
            "Resolving www.nuscenes.org (www.nuscenes.org)... 13.227.219.76, 13.227.219.6, 13.227.219.18, ...\n",
            "Connecting to www.nuscenes.org (www.nuscenes.org)|13.227.219.76|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4167696325 (3.9G) [application/x-tar]\n",
            "Saving to: ‘v1.0-mini.tgz’\n",
            "\n",
            "v1.0-mini.tgz       100%[===================>]   3.88G  86.0MB/s    in 46s     \n",
            "\n",
            "2023-10-20 18:24:40 (86.9 MB/s) - ‘v1.0-mini.tgz’ saved [4167696325/4167696325]\n",
            "\n",
            "--2023-10-20 18:24:40--  https://www.nuscenes.org/data/nuScenes-lidarseg-mini-v1.0.tar.bz2\n",
            "Resolving www.nuscenes.org (www.nuscenes.org)... 13.227.219.6, 13.227.219.76, 13.227.219.45, ...\n",
            "Connecting to www.nuscenes.org (www.nuscenes.org)|13.227.219.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1819477 (1.7M) [application/x-tar]\n",
            "Saving to: ‘nuScenes-lidarseg-mini-v1.0.tar.bz2’\n",
            "\n",
            "nuScenes-lidarseg-m 100%[===================>]   1.73M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2023-10-20 18:24:40 (64.7 MB/s) - ‘nuScenes-lidarseg-mini-v1.0.tar.bz2’ saved [1819477/1819477]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p /data/sets/nuscenes  # Make the directory to store the nuScenes dataset in.\n",
        "\n",
        "!wget https://www.nuscenes.org/data/v1.0-mini.tgz  # Download the nuScenes mini split.\n",
        "!wget https://www.nuscenes.org/data/nuScenes-lidarseg-mini-v1.0.tar.bz2  # Download the nuScenes-lidarseg mini split.\n",
        "\n",
        "!tar -xf v1.0-mini.tgz -C /data/sets/nuscenes  # Uncompress the nuScenes mini split.\n",
        "!tar -xf nuScenes-lidarseg-mini-v1.0.tar.bz2 -C /data/sets/nuscenes   # Uncompress the nuScenes-lidarseg mini split.\n",
        "!pip install nuscenes-devkit &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2EAOy175s9_",
        "outputId": "f6e9bb83-49d1-4120-f0f9-60429f617f2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======\n",
            "Loading NuScenes tables for version v1.0-mini...\n",
            "Loading nuScenes-lidarseg...\n",
            "32 category,\n",
            "8 attribute,\n",
            "4 visibility,\n",
            "911 instance,\n",
            "12 sensor,\n",
            "120 calibrated_sensor,\n",
            "31206 ego_pose,\n",
            "8 log,\n",
            "10 scene,\n",
            "404 sample,\n",
            "31206 sample_data,\n",
            "18538 sample_annotation,\n",
            "4 map,\n",
            "404 lidarseg,\n",
            "Done loading in 0.841 seconds.\n",
            "======\n",
            "Reverse indexing ...\n",
            "Done reverse indexing in 0.1 seconds.\n",
            "======\n",
            "/\n"
          ]
        }
      ],
      "source": [
        "from nuscenes import NuScenes\n",
        "from nuscenes.eval.prediction.splits import get_prediction_challenge_split\n",
        "from nuscenes.prediction import PredictHelper\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from nuscenes.prediction import PredictHelper\n",
        "DATAROOT = '/data/sets/nuscenes'\n",
        "ns = NuScenes('v1.0-mini', dataroot=DATAROOT , verbose=True)\n",
        "helper = PredictHelper(ns)\n",
        "import os\n",
        "os.chdir('..')\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ot1yrqaD4-JT"
      },
      "outputs": [],
      "source": [
        "ped_cat = ['human.pedestrian.adult','human.pedestrian.child','human.pedestrian.construction_worker',\n",
        "           'human.pedestrian.personal_mobility',\n",
        "           'human.pedestrian.police_officer']\n",
        "def calculate_ped_trajectory(ped_cat):\n",
        "    count = 0\n",
        "    dict_of_trajectory = {}\n",
        "    selected_pedestrain = []\n",
        "    for attr in ns.sample_annotation:\n",
        "\n",
        "      if attr['category_name'] in ped_cat:\n",
        "        if len(attr['prev']) < 2 :\n",
        "          token          = attr['token']\n",
        "          sample_token   = attr['sample_token']\n",
        "          instance_token = attr['instance_token']\n",
        "          future_xy_local = helper.get_future_for_agent(instance_token, sample_token, seconds=20, in_agent_frame=False , just_xy=False)\n",
        "          dict_of_trajectory[attr['instance_token'] +'_'+ attr['sample_token']] = future_xy_local\n",
        "\n",
        "    list_of_trajectory = list(dict_of_trajectory.values())\n",
        "    return list_of_trajectory ,dict_of_trajectory\n",
        "#list of all trajectory in the mini_nuscenes dataset\n",
        "list_of_trajectory  , dict_of_trajectory = calculate_ped_trajectory(ped_cat)\n",
        "list_of_trajectory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LX-1mSQr-sau"
      },
      "outputs": [],
      "source": [
        "def grouped_scene_seq_func(list_of_trajectory):\n",
        "    scene_seq_list = []\n",
        "    for i in range(len(list_of_trajectory)):\n",
        "        sub_list = []\n",
        "        if len(list_of_trajectory[i]) == 0:\n",
        "          continue\n",
        "        sample_token = list_of_trajectory[i][0]['sample_token']\n",
        "        #find scene token for trajectories\n",
        "        scene_token = ns.get('sample' , sample_token)['scene_token']\n",
        "        sub_list.append(scene_token)\n",
        "        sub_list.append(list_of_trajectory[i])\n",
        "        #list that first item is scene token and second item is trajectory in that scene\n",
        "        scene_seq_list.append(sub_list)\n",
        "    #groupby according to scene_token((all trajectory in the scene now are in same list))\n",
        "    grouped_scene_seq = {}\n",
        "    for sublist in scene_seq_list:\n",
        "        key = sublist[0]\n",
        "        if key in grouped_scene_seq.keys():\n",
        "            grouped_scene_seq[key].append(sublist[1])\n",
        "        else:\n",
        "            grouped_scene_seq[key] = [sublist[1]]\n",
        "    return grouped_scene_seq\n",
        "#scene_seq_list is a dictionary that key is scene token and values are all pedestrain trajectory in this key\n",
        "grouped_scene_seq = grouped_scene_seq_func(list_of_trajectory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bhvbYhp_PpKC"
      },
      "outputs": [],
      "source": [
        "scene_agg_list = []\n",
        "for scene_token in grouped_scene_seq.keys():\n",
        "      sequences = grouped_scene_seq[scene_token]\n",
        "      agg_seq = []\n",
        "      for sequence in sequences:\n",
        "          instance_token , sample_token =   sequence[0]['instance_token'] , sequence[0]['sample_token']\n",
        "          past = helper.get_past_for_agent(instance_token ,sample_token , seconds=20 ,in_agent_frame=False )\n",
        "          future = helper.get_future_for_agent(instance_token  , sample_token , seconds=20 ,in_agent_frame=False )\n",
        "          if len(future) ==0:\n",
        "            continue\n",
        "          seq = np.append(past ,future , axis=0)\n",
        "          agg_seq.append(seq)\n",
        "      scene_agg_list.append(agg_seq)\n",
        "#creat file for each scene(each file contain all pedestrain and trajectory according to eth and ucy format)\n",
        "      scene  = scene_token\n",
        "      for temp in scene_agg_list:\n",
        "          file_path = f'/content/{scene} +.txt'\n",
        "          ped_id = 0\n",
        "          with open (file_path , 'a') as f:\n",
        "            for seq in temp:\n",
        "                ped_id+=1\n",
        "                for frame_number , xy in enumerate(seq):\n",
        "                    f.write(f\"{frame_number}  {ped_id}  {xy[0]}  {xy[1]}\\n\")\n",
        "          with open(f'/content/{scene} +.txt', 'r') as file:\n",
        "            lines = file.readlines()\n",
        "\n",
        "          rows = [line.strip().split() for line in lines]\n",
        "          sorted_rows = sorted(rows, key=lambda x: int(x[0]))\n",
        "          sorted_lines = [' '.join(row) + '\\n' for row in sorted_rows]\n",
        "\n",
        "          # Save the sorted data to a new file\n",
        "          with open(f'/content/scene_id:{scene}+.txt', 'w') as output_file:\n",
        "              output_file.writelines(sorted_lines)\n",
        "              os.remove(f'/content/{scene} +.txt')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
